{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "MLPEvaluation.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIoldk7BBmdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "0e8a1fd4-ba49-43a2-fe87-f66685d5aadc"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, BorderlineSMOTE\n",
        "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "#from sklearn.metrics.roc_auc_score\n",
        "from sklearn import svm\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "scaler = StandardScaler()  \n",
        "\n",
        "X = pd.read_csv('features.csv',encoding='windows-1252',sep=',')\n",
        "\n",
        "X.fillna(value=0, inplace=True)\n",
        "\n",
        "X.guten_genre = pd.factorize(X.guten_genre)[0]\n",
        "X['index1'] = X.index\n",
        "\n",
        "#y = X.guten_genre#.get_dummies()\n",
        "y = X.guten_genre #dumiies\n",
        "\n",
        "#lb = LabelBinarizer()\n",
        "#y = lb.fit_transform(X.guten_genre)\n",
        "\n",
        "print(y)\n",
        "\n",
        "X = X.drop('guten_genre', 1)\n",
        "\n",
        "X.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      0\n",
            "1      1\n",
            "2      1\n",
            "3      2\n",
            "4      1\n",
            "      ..\n",
            "991    1\n",
            "992    1\n",
            "993    0\n",
            "994    0\n",
            "995    1\n",
            "Name: guten_genre, Length: 996, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p_tag_count</th>\n",
              "      <th>comma_count</th>\n",
              "      <th>colon_count</th>\n",
              "      <th>hyphen_count</th>\n",
              "      <th>TTR</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>Negative</th>\n",
              "      <th>FleschK_score</th>\n",
              "      <th>CC</th>\n",
              "      <th>PRP</th>\n",
              "      <th>PRP$</th>\n",
              "      <th>IN</th>\n",
              "      <th>NNP</th>\n",
              "      <th>period_count</th>\n",
              "      <th>index1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2283</td>\n",
              "      <td>5669</td>\n",
              "      <td>18</td>\n",
              "      <td>850</td>\n",
              "      <td>0.154</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.673</td>\n",
              "      <td>0.133</td>\n",
              "      <td>51.398</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>688.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>382883</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>268</td>\n",
              "      <td>962</td>\n",
              "      <td>54</td>\n",
              "      <td>311</td>\n",
              "      <td>0.348</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.651</td>\n",
              "      <td>0.118</td>\n",
              "      <td>41.849</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>104178</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3510</td>\n",
              "      <td>11771</td>\n",
              "      <td>415</td>\n",
              "      <td>2664</td>\n",
              "      <td>0.113</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.618</td>\n",
              "      <td>0.142</td>\n",
              "      <td>58.161</td>\n",
              "      <td>23.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>1473.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>821156</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3332</td>\n",
              "      <td>5798</td>\n",
              "      <td>17</td>\n",
              "      <td>1358</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.164</td>\n",
              "      <td>0.729</td>\n",
              "      <td>0.107</td>\n",
              "      <td>64.087</td>\n",
              "      <td>56.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>506644</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>472</td>\n",
              "      <td>1429</td>\n",
              "      <td>39</td>\n",
              "      <td>282</td>\n",
              "      <td>0.262</td>\n",
              "      <td>0.254</td>\n",
              "      <td>0.587</td>\n",
              "      <td>0.159</td>\n",
              "      <td>54.611</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98120</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   p_tag_count  comma_count  colon_count  ...   NNP  period_count  index1\n",
              "0         2283         5669           18  ...  17.0        382883       0\n",
              "1          268          962           54  ...   4.0        104178       1\n",
              "2         3510        11771          415  ...  23.0        821156       2\n",
              "3         3332         5798           17  ...  23.0        506644       3\n",
              "4          472         1429           39  ...   1.0         98120       4\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KPIyXAIBmeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f788b648-87c2-4907-ea40-a06f3ef8dc2e"
      },
      "source": [
        "modeller = TopicModeller()\n",
        "modeller.setNumberOfTopics(4)\n",
        "modeller.setPercentage(0.1)\n",
        "modeller.loadData( 'prepared_tokens.npy' )\n",
        "\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
        "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \n",
        "         \"Naive Bayes\", \"QDA\"]\n",
        "\n",
        "#classifiers = [\n",
        "   #GaussianNB(),\n",
        "   #KNeighborsClassifier(5),\n",
        "   #DecisionTreeClassifier(max_depth=5),\n",
        "  # MLPClassifier(solver='lbfgs', alpha=0.000001, random_state=None)\n",
        " #                   #hidden_layer_sizes=(5, 2), \n",
        "#]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "sm = SMOTE(random_state = None, k_neighbors=1)\n",
        "\n",
        "#skf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "#ros = RandomOverSampler(random_state=None)\n",
        "#rus = RandomUnderSampler(random_state=None)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
        "\n",
        "df_train, df_test = modeller.getFeatures(X_train.index1, X_test.index1)    \n",
        "\n",
        "X_train = X_train.join(df_train)\n",
        "X_test = X_test.join(df_test)\n",
        "X_train.fillna(value=0, inplace=True)\n",
        "X_test.fillna(value=0, inplace=True)\n",
        "\n",
        "\n",
        "X_train = X_train.drop('index1',axis=1)\n",
        "X_test = X_test.drop('index1',axis=1)\n",
        "#X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
        "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
        "#X_resampled, y_resampled = ADASYN(n_neighbors=1).fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "scaler.fit(X_resampled) \n",
        "    \n",
        "X_resampled = scaler.transform(X_resampled)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "for name, clf in zip(names,classifiers):\n",
        "  clf.fit(X_resampled, y_resampled)\n",
        "  score = clf.score(X_test, y_test)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(str(name) + \", Accuracy: \" + str(score) + \", F1-Score: \" + str(f1_score(y_test,y_pred, average = 'weighted')))\n",
        " \n",
        "\n",
        "  #y_test = lb.inverse_transform(y_test, threshold=None)\n",
        "  #y_pred = lb.inverse_transform(y_pred)\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "  print('###########')\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearest Neighbors, Accuracy: 0.505, F1-Score: 0.5746080586080586\n",
            "[[ 7 11  0  0  0  0  4  0  0]\n",
            " [30 94  2  1  3  8 19  1  2]\n",
            " [ 0  1  0  0  0  1  2  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0]\n",
            " [ 0  4  0  0  0  0  0  0  0]\n",
            " [ 5  2  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0]]\n",
            "###########\n",
            "Linear SVM, Accuracy: 0.465, F1-Score: 0.5492428320160283\n",
            "[[10  6  2  0  0  1  3  0  0]\n",
            " [19 79  6  9  2 11 24  1  9]\n",
            " [ 0  3  0  0  0  0  1  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  1  2  0  0  0]\n",
            " [ 2  2  0  1  0  0  2  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0]]\n",
            "###########\n",
            "RBF SVM, Accuracy: 0.8, F1-Score: 0.7111111111111111\n",
            "[[  0  22   0   0   0   0   0   0]\n",
            " [  0 160   0   0   0   0   0   0]\n",
            " [  0   4   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0]\n",
            " [  0   4   0   0   0   0   0   0]\n",
            " [  0   7   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0]]\n",
            "###########\n",
            "Decision Tree, Accuracy: 0.33, F1-Score: 0.43703837644656224\n",
            "[[ 1  3  0  0  0  8 10  0]\n",
            " [ 8 60  5  0  2 44 39  2]\n",
            " [ 0  0  0  0  0  1  3  0]\n",
            " [ 0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0]\n",
            " [ 0  2  0  1  0  0  0  1]\n",
            " [ 1  0  0  0  0  1  5  0]\n",
            " [ 0  0  0  0  0  0  1  0]]\n",
            "###########\n",
            "Random Forest, Accuracy: 0.345, F1-Score: 0.44172014260249554\n",
            "[[ 3  9  2  0  0  5  1  2  0]\n",
            " [ 8 62 14 10  1 33 19  4  9]\n",
            " [ 0  0  1  1  1  0  1  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  2  0  0  1]\n",
            " [ 2  4  0  0  0  0  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0]]\n",
            "###########\n",
            "Neural Net, Accuracy: 0.635, F1-Score: 0.6799262632834526\n",
            "[[ 12   8   1   0   0   1   0   0   0]\n",
            " [ 16 113   5   4   1   5   9   1   6]\n",
            " [  0   2   0   0   0   0   2   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0]\n",
            " [  0   4   0   0   0   0   0   0   0]\n",
            " [  3   1   0   1   0   0   2   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0]]\n",
            "###########\n",
            "Naive Bayes, Accuracy: 0.17, F1-Score: 0.25401212121212124\n",
            "[[ 1  2  0  3  0  3  0 13]\n",
            " [ 2 29  3 16 11 55  5 39]\n",
            " [ 0  1  0  0  1  1  0  1]\n",
            " [ 0  0  0  0  1  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0]\n",
            " [ 0  0  0  1  0  2  0  1]\n",
            " [ 0  2  0  0  0  1  1  3]\n",
            " [ 0  1  0  0  0  0  0  0]]\n",
            "###########\n",
            "QDA, Accuracy: 0.755, F1-Score: 0.7367857142857145\n",
            "[[ 13   9   0   0   0   0   0   0]\n",
            " [ 18 138   0   0   0   0   4   0]\n",
            " [  0   4   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0]\n",
            " [  0   4   0   0   0   0   0   0]\n",
            " [  3   4   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0]]\n",
            "###########\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLaZljYUBmeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class TopicModeller():\n",
        "\n",
        "  def __init__( self ):\n",
        "    self.genres = []\n",
        "    self.books = []\n",
        "    self.NUM_TOPICS = 10\n",
        "    self.PERCENTAGE = 0.2\n",
        "\n",
        "  def setNumberOfTopics( self, value ):\n",
        "    self.NUM_TOPICS = value\n",
        "\n",
        "  def setPercentage( self, value ):\n",
        "    self.PERCENTAGE = value\n",
        "\n",
        "  def loadData( self, path ):\n",
        "    with open(path, 'rb') as f:\n",
        "        self.genres = np.load(f, allow_pickle=True)\n",
        "        self.books = np.load(f, allow_pickle=True)\n",
        "\n",
        "  def getFeatures( self, trainIndices, testIndices ):\n",
        "\n",
        "    books_train, books_test = self.books[trainIndices], self.books[testIndices]\n",
        "    genres_train, genres_test = self.genres[trainIndices], self.genres[testIndices]\n",
        "\n",
        "    arr = []\n",
        "\n",
        "    for i in range( len(genres_train ) ):\n",
        "      if genres_train[i] == 'Literary':\n",
        "        val = random.random()\n",
        "        if val > self.PERCENTAGE:\n",
        "          continue\n",
        "      arr.append( books_train[i])\n",
        "\n",
        "    # Create the topics\n",
        "    NUM_WORDS  = 4\n",
        "\n",
        "    dictionary = corpora.Dictionary( arr )\n",
        "    dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
        "    corpus = [ dictionary.doc2bow( text ) for text in arr ]\n",
        "\n",
        "    # Set training parameters.\n",
        "    num_topics = self.NUM_TOPICS\n",
        "    chunksize = 2000\n",
        "    passes = 20\n",
        "    iterations = 400\n",
        "    eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "    # Make a index to word dictionary.\n",
        "    temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "    id2word = dictionary.id2token\n",
        "\n",
        "    ldamodel = gensim.models.ldamodel.LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=id2word,\n",
        "        chunksize=chunksize,\n",
        "        alpha='auto',\n",
        "        eta='auto',\n",
        "        iterations=iterations,\n",
        "        num_topics=num_topics,\n",
        "        passes=passes,\n",
        "        eval_every=eval_every\n",
        "    )\n",
        "\n",
        "    # Print out the topics\n",
        "    topics = ldamodel.print_topics( num_words=NUM_WORDS )\n",
        "    #print(\"The following topics were generated:\")\n",
        "    #for topic in topics:\n",
        "      #print( topic )\n",
        "\n",
        "    # Process the books and get final training data\n",
        "    X_train = []\n",
        "    Y_train = genres_train # TODO do I have to preprocess it as well?\n",
        "\n",
        "    for book in books_train:\n",
        "\n",
        "      # Get the topic weights\n",
        "      bow = dictionary.doc2bow( book )\n",
        "      topics = ldamodel.get_document_topics( bow )\n",
        "\n",
        "      # Convert the vector of dynamic length to\n",
        "      # constant length feature vector\n",
        "      x = [0] * self.NUM_TOPICS\n",
        "      for topic in topics:\n",
        "        x[topic[0]] = topic[1]\n",
        "      X_train.append(x)\n",
        "\n",
        "    # Prepare our test data in the same way\n",
        "    X_test = []\n",
        "    Y_test = genres_test # TODO do I have to preprocess it as well?\n",
        "\n",
        "    for book in books_test:\n",
        "\n",
        "      # Get the topic weights\n",
        "      bow = dictionary.doc2bow( book )\n",
        "      topics = ldamodel.get_document_topics(bow)\n",
        "\n",
        "      # Convert the vector of dynamic length to\n",
        "      # constant length feature vector\n",
        "      x = [0] * self.NUM_TOPICS\n",
        "      for topic in topics:\n",
        "        x[topic[0]] = topic[1]\n",
        "      X_test.append(x)\n",
        "    df_train = pd.DataFrame()\n",
        "    df_test =  pd.DataFrame()\n",
        "    for i in range(self.NUM_TOPICS):\n",
        "        column = [entity[i] for entity in X_train]\n",
        "        column2 = [entity[i] for entity in X_test]\n",
        "        df_train[\"topic\" + str(i)] = column\n",
        "        df_test[\"topic\" + str(i)] = column2\n",
        "    return df_train, df_test"
      ],
      "execution_count": 54,
      "outputs": []
    }
  ]
}