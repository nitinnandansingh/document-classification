{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TopicModellingClass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOESV6xpdC3nZo7D0H2tbpj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bostelma/ATiML-Project/blob/master/TopicModellingClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP2lMEdfqJ0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7pLl8r1qS9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TopicModeller():\n",
        "\n",
        "  def __init__( self ):\n",
        "    self.genres = []\n",
        "    self.books = []\n",
        "    self.NUM_TOPICS = 10\n",
        "    self.PERCENTAGE = 0.2\n",
        "\n",
        "  def setNumberOfTopics( self, value ):\n",
        "    self.NUM_TOPICS = value\n",
        "\n",
        "  def setPercentage( self, value ):\n",
        "    self.PERCENTAGE = value\n",
        "\n",
        "  def loadData( self, path ):\n",
        "    with open(path, 'rb') as f:\n",
        "        self.genres = np.load(f, allow_pickle=True)\n",
        "        self.books = np.load(f, allow_pickle=True)\n",
        "\n",
        "  def getFeatures( self, trainIndices, testIndices ):\n",
        "\n",
        "    books_train, books_test = self.books[trainIndices], self.books[testIndices]\n",
        "    genres_train, genres_test = self.genres[trainIndices], self.genres[testIndices]\n",
        "\n",
        "    arr = []\n",
        "\n",
        "    for i in range( len(genres_train ) ):\n",
        "      if genres_train[i] == 'Literary':\n",
        "        val = random.random()\n",
        "        if val > self.PERCENTAGE:\n",
        "          continue\n",
        "      arr.append( books_train[i])\n",
        "\n",
        "    # Create the topics\n",
        "    NUM_WORDS  = 4\n",
        "\n",
        "    dictionary = corpora.Dictionary( arr )\n",
        "    dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
        "    corpus = [ dictionary.doc2bow( text ) for text in arr ]\n",
        "\n",
        "    # Set training parameters.\n",
        "    num_topics = self.NUM_TOPICS\n",
        "    chunksize = 2000\n",
        "    passes = 20\n",
        "    iterations = 400\n",
        "    eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "    # Make a index to word dictionary.\n",
        "    temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "    id2word = dictionary.id2token\n",
        "\n",
        "    ldamodel = gensim.models.ldamodel.LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=id2word,\n",
        "        chunksize=chunksize,\n",
        "        alpha='auto',\n",
        "        eta='auto',\n",
        "        iterations=iterations,\n",
        "        num_topics=num_topics,\n",
        "        passes=passes,\n",
        "        eval_every=eval_every\n",
        "    )\n",
        "\n",
        "    # Print out the topics\n",
        "    topics = ldamodel.print_topics( num_words=NUM_WORDS )\n",
        "    print(\"The following topics were generated:\")\n",
        "    for topic in topics:\n",
        "      print( topic )\n",
        "\n",
        "    # Process the books and get final training data\n",
        "    X_train = []\n",
        "    Y_train = genres_train # TODO do I have to preprocess it as well?\n",
        "\n",
        "    for book in books_train:\n",
        "\n",
        "      # Get the topic weights\n",
        "      bow = dictionary.doc2bow( book )\n",
        "      topics = ldamodel.get_document_topics( bow )\n",
        "\n",
        "      # Convert the vector of dynamic length to\n",
        "      # constant length feature vector\n",
        "      x = [0] * self.NUM_TOPICS\n",
        "      for topic in topics:\n",
        "        x[topic[0]] = topic[1]\n",
        "      X_train.append(x)\n",
        "\n",
        "    # Prepare our test data in the same way\n",
        "    X_test = []\n",
        "    Y_test = genres_test # TODO do I have to preprocess it as well?\n",
        "\n",
        "    for book in books_test:\n",
        "\n",
        "      # Get the topic weights\n",
        "      bow = dictionary.doc2bow( book )\n",
        "      topics = ldamodel.get_document_topics(bow)\n",
        "\n",
        "      # Convert the vector of dynamic length to\n",
        "      # constant length feature vector\n",
        "      x = [0] * self.NUM_TOPICS\n",
        "      for topic in topics:\n",
        "        x[topic[0]] = topic[1]\n",
        "      X_test.append(x)\n",
        "\n",
        "    return X_test, X_train, Y_test, Y_train"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LUYnB6VvYr4",
        "colab_type": "text"
      },
      "source": [
        "Example code on how to use this class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHkgsi1Ut8Ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "e2352b6d-e818-4c36-9f78-35773c81199f"
      },
      "source": [
        "modeller = TopicModeller()#\n",
        "modeller.loadData( 'prepared_tokens.npy' )\n",
        "\n",
        "NUMBER_OF_SPLITS = 5\n",
        "TEST_SIZE = 1 / 3\n",
        "\n",
        "sss = StratifiedShuffleSplit(\n",
        "    n_splits=NUMBER_OF_SPLITS,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "splits = sss.split( modeller.books, modeller.genres )\n",
        "\n",
        "train_index = []\n",
        "test_index = []\n",
        "\n",
        "for tr, te in splits:\n",
        "  train_index = tr\n",
        "  test_index = te\n",
        "\n",
        "X_test, X_train, Y_test, Y_train = modeller.getFeatures( train_index, test_index )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following topics were generated:\n",
            "(0, '0.005*\"judge\" + 0.004*\"james\" + 0.003*\"hill\" + 0.003*\"flower\"')\n",
            "(1, '0.004*\"uncle\" + 0.004*\"london\" + 0.003*\"england\" + 0.002*\"fortune\"')\n",
            "(2, '0.015*\"ship\" + 0.013*\"captain\" + 0.008*\"deck\" + 0.006*\"boat\"')\n",
            "(3, '0.005*\"aunt\" + 0.004*\"desert\" + 0.003*\"uncle\" + 0.003*\"lovely\"')\n",
            "(4, '0.006*\"horse\" + 0.004*\"indian\" + 0.002*\"shadow\" + 0.002*\"spot\"')\n",
            "(5, '0.005*\"captain\" + 0.005*\"detective\" + 0.003*\"count\" + 0.003*\"jewel\"')\n",
            "(6, '0.004*\"grace\" + 0.003*\"hall\" + 0.003*\"american\" + 0.003*\"squire\"')\n",
            "(7, '0.003*\"train\" + 0.003*\"detective\" + 0.003*\"towards\" + 0.003*\"shook\"')\n",
            "(8, '0.005*\"mary\" + 0.004*\"lord\" + 0.004*\"robert\" + 0.003*\"towards\"')\n",
            "(9, '0.011*\"john\" + 0.008*\"temple\" + 0.006*\"hall\" + 0.004*\"uncle\"')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}