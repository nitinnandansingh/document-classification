{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "     p_tag_count  comma_count  colon_count  hyphen_count    TTR  Positive  \\\n",
      "718         5335        13662          296          2045  0.086     0.314   \n",
      "196         2145         7124           42          2270  0.155     0.178   \n",
      "482          923         4349          104          1058  0.193     0.228   \n",
      "590         1557         3367           29           921  0.218     0.188   \n",
      "898         2701         4811          121          1400  0.212     0.170   \n",
      "793         2314         6212           24          1209  0.156     0.223   \n",
      "345          343         4153           39           913  0.181     0.191   \n",
      "582         1713         7260          111           995  0.185     0.204   \n",
      "886          180          631           17           139  0.383     0.251   \n",
      "138         2496         6972           45          1935  0.172     0.254   \n",
      "913         2913        13821          146          2557  0.103     0.263   \n",
      "169         1789         6849          118          1689  0.183     0.237   \n",
      "475         2897        10042          161          3589  0.145     0.230   \n",
      "152          907         1392           17           406  0.310     0.233   \n",
      "20          2947        13926          145          4447  0.106     0.146   \n",
      "957         2280         6474          196          1802  0.173     0.205   \n",
      "222          556         2653           17           237  0.276     0.216   \n",
      "534         1238         4839           36           999  0.207     0.257   \n",
      "236         1209         5259           72           768  0.230     0.206   \n",
      "175          348          775           16           106  0.274     0.176   \n",
      "555          527         3570           62           317  0.252     0.237   \n",
      "662          769         3673           43           429  0.239     0.197   \n",
      "991         7081        36118          454          4474  0.078     0.227   \n",
      "645         1422         3401           54           579  0.188     0.222   \n",
      "216          896         2944           25           407  0.213     0.224   \n",
      "226          619         6280           48          1000  0.170     0.188   \n",
      "939         3625         9002           98          4732  0.128     0.207   \n",
      "646         2374         8956           35          1039  0.187     0.208   \n",
      "701         1034         3996           55           734  0.239     0.244   \n",
      "541         1609         4022          192          1135  0.162     0.160   \n",
      "..           ...          ...          ...           ...    ...       ...   \n",
      "299         1697         1687          107           154  0.246     0.154   \n",
      "817         2156         4459           64           708  0.183     0.225   \n",
      "38           868         1981           20           261  0.216     0.307   \n",
      "248          236          691            5           125  0.408     0.230   \n",
      "987          944          821            2           246  0.241     0.167   \n",
      "280          284         1255           10           421  0.352     0.165   \n",
      "106         4936        13857          280          1739  0.112     0.207   \n",
      "491           82          575            3            78  0.508     0.249   \n",
      "302         1876         5325           71           875  0.164     0.204   \n",
      "283         1103         6274           65          1104  0.163     0.206   \n",
      "593         2340         5410           90          1235  0.224     0.175   \n",
      "407         3496         9892            3          3200  0.106     0.231   \n",
      "502          441         2887          246           211  0.246     0.244   \n",
      "444         2645         5960           82          1102  0.146     0.274   \n",
      "31           310         1044           10           156  0.360     0.259   \n",
      "151         2322         4245           66           495  0.178     0.245   \n",
      "298          984         4532          532           718  0.202     0.264   \n",
      "109         4341         9718           41          2913  0.109     0.257   \n",
      "810         1829         4639           72           829  0.137     0.191   \n",
      "61          1493        15184          193           757  0.122     0.247   \n",
      "917          243          511           23           210  0.465     0.200   \n",
      "827         1762         8008          116           744  0.106     0.249   \n",
      "621         1678         5580           54          1050  0.166     0.167   \n",
      "536         1127         4596           30           952  0.189     0.215   \n",
      "84           555         1712           28           325  0.224     0.268   \n",
      "512         1310         3935           18           639  0.199     0.154   \n",
      "740          803         1441           18           641  0.265     0.218   \n",
      "414         2415        16733          167          3211  0.146     0.212   \n",
      "128         1866         8153          160          1533  0.183     0.217   \n",
      "815          621         3450           78           901  0.237     0.230   \n",
      "\n",
      "     Neutral  Negative  FleschK_score    CC   PRP  PRP$      IN    NNP  \\\n",
      "718    0.558     0.128         58.499  67.0  17.0     4  1567.0   30.0   \n",
      "196    0.696     0.127         50.720  72.0   9.0     0  1380.0   23.0   \n",
      "482    0.644     0.128         48.648  15.0   3.0     1   624.0    4.0   \n",
      "590    0.671     0.141         51.023  22.0   5.0     2   734.0   13.0   \n",
      "898    0.715     0.116         41.756  20.0   1.0     0   676.0   21.0   \n",
      "793    0.652     0.125         56.176  30.0   6.0     3   497.0   35.0   \n",
      "345    0.638     0.171         43.665  23.0   4.0     2   667.0    5.0   \n",
      "582    0.652     0.143         43.663  31.0   7.0     4  1024.0   19.0   \n",
      "886    0.606     0.143         62.859   0.0   0.0     0   110.0    2.0   \n",
      "138    0.607     0.139         53.878  28.0   7.0     2   659.0   22.0   \n",
      "913    0.590     0.147         54.647  34.0   8.0     5  1569.0   51.0   \n",
      "169    0.647     0.116         45.067  27.0   6.0     1   751.0   33.0   \n",
      "475    0.627     0.143         43.868  91.0  11.0     2  1861.0    9.0   \n",
      "152    0.647     0.120         48.018  13.0   0.0     0   268.0    5.0   \n",
      "20     0.721     0.133         55.810  51.0  12.0     4  2203.0   35.0   \n",
      "957    0.672     0.122         51.347  20.0  14.0     2  1099.0   34.0   \n",
      "222    0.662     0.122         54.341  20.0   4.0     1   332.0    8.0   \n",
      "534    0.635     0.109         43.270  29.0   7.0     3   642.0    4.0   \n",
      "236    0.665     0.128         43.382  12.0   8.0     1   493.0    5.0   \n",
      "175    0.676     0.148         51.469   6.0   3.0     0   140.0    4.0   \n",
      "555    0.645     0.118         29.272  29.0   1.0     0   364.0    2.0   \n",
      "662    0.630     0.173         35.339  36.0   3.0     3   504.0   12.0   \n",
      "991    0.654     0.119         49.398  94.0  26.0    17  3931.0  522.0   \n",
      "645    0.628     0.150         56.958  24.0   1.0     2   659.0   18.0   \n",
      "216    0.702     0.074         49.485  17.0   4.0     0   631.0    6.0   \n",
      "226    0.723     0.089         38.949  29.0   3.0     6  1097.0   14.0   \n",
      "939    0.654     0.138         46.709  46.0  16.0     3  1623.0   25.0   \n",
      "646    0.649     0.143         47.501  35.0   8.0     3  1173.0   37.0   \n",
      "701    0.618     0.138         40.531  22.0   7.0     0   694.0    9.0   \n",
      "541    0.704     0.136         60.726  10.0   3.0     2   730.0   12.0   \n",
      "..       ...       ...            ...   ...   ...   ...     ...    ...   \n",
      "299    0.694     0.152         56.404   6.0   1.0     0   324.0   11.0   \n",
      "817    0.641     0.135         50.536  38.0   3.0     3   763.0   29.0   \n",
      "38     0.583     0.110         57.771   8.0   4.0     2   258.0    5.0   \n",
      "248    0.648     0.122         48.475   0.0   1.0     1    96.0    1.0   \n",
      "987    0.742     0.090         60.424   2.0   0.0     0   183.0    2.0   \n",
      "280    0.702     0.133         53.949   5.0   4.0     0   215.0   17.0   \n",
      "106    0.649     0.144         46.405  60.0  11.0     7  1667.0   29.0   \n",
      "491    0.647     0.104         50.351   1.0   0.0     0    64.0    1.0   \n",
      "302    0.632     0.164         35.803  16.0   4.0     1   870.0   11.0   \n",
      "283    0.667     0.126         50.182  20.0   9.0     1   973.0   28.0   \n",
      "593    0.715     0.110         49.163  13.0   4.0     0   560.0   28.0   \n",
      "407    0.611     0.158         54.439  58.0   3.0     9  1399.0   21.0   \n",
      "502    0.599     0.157         38.401  20.0   0.0     0   371.0    4.0   \n",
      "444    0.615     0.111         36.297  38.0  17.0     2  1086.0   15.0   \n",
      "31     0.584     0.157         42.358   6.0   0.0     0   112.0   23.0   \n",
      "151    0.635     0.121         56.160  15.0   3.0     0   653.0   24.0   \n",
      "298    0.609     0.127         55.307  23.0   9.0     1   625.0   10.0   \n",
      "109    0.583     0.160         60.191  23.0  12.0     3  1353.0   14.0   \n",
      "810    0.679     0.130         54.547  13.0   7.0     5   914.0   30.0   \n",
      "61     0.641     0.112         42.136  79.0  14.0    15  2017.0   29.0   \n",
      "917    0.700     0.100         46.068   0.0   0.0     0    79.0    8.0   \n",
      "827    0.599     0.152         60.823  14.0  16.0     3  1113.0   17.0   \n",
      "621    0.716     0.117         49.581  36.0   4.0     3  1138.0   13.0   \n",
      "536    0.630     0.156         42.984  28.0   5.0     0   636.0    8.0   \n",
      "84     0.566     0.165         65.762  12.0   1.0     0   215.0    3.0   \n",
      "512    0.716     0.130         52.740  21.0  10.0     0   714.0   32.0   \n",
      "740    0.636     0.146         60.967   7.0   4.0     1   266.0   14.0   \n",
      "414    0.665     0.123         40.731  96.0   7.0     9  2159.0   41.0   \n",
      "128    0.640     0.144         35.776  27.0  15.0     5   928.0   23.0   \n",
      "815    0.617     0.153         48.032  13.0   4.0     0   547.0    6.0   \n",
      "\n",
      "     period_count  \n",
      "718        923737  \n",
      "196        607441  \n",
      "482        299751  \n",
      "590        335497  \n",
      "898        400982  \n",
      "793        357469  \n",
      "345        306593  \n",
      "582        431342  \n",
      "886         46617  \n",
      "138        428751  \n",
      "913        976929  \n",
      "169        466865  \n",
      "475        830820  \n",
      "152        131776  \n",
      "20         898175  \n",
      "957        488360  \n",
      "222        182392  \n",
      "534        337603  \n",
      "236        323409  \n",
      "175         84060  \n",
      "555        216468  \n",
      "662        247262  \n",
      "991       1967040  \n",
      "645        292814  \n",
      "216        277856  \n",
      "226        447041  \n",
      "939        847011  \n",
      "646        535171  \n",
      "701        331147  \n",
      "541        374893  \n",
      "..            ...  \n",
      "299        148778  \n",
      "817        425413  \n",
      "38         145540  \n",
      "248         52645  \n",
      "987         72770  \n",
      "280        103577  \n",
      "106        911515  \n",
      "491         29254  \n",
      "302        417242  \n",
      "283        544196  \n",
      "593        379577  \n",
      "407        838804  \n",
      "502        168499  \n",
      "444        596885  \n",
      "31          82349  \n",
      "151        386589  \n",
      "298        332915  \n",
      "109        642658  \n",
      "810        405737  \n",
      "61         940032  \n",
      "917         49068  \n",
      "827        548588  \n",
      "621        438393  \n",
      "536        369904  \n",
      "84         122536  \n",
      "512        302850  \n",
      "740        117906  \n",
      "414       1020088  \n",
      "128        536059  \n",
      "815        211943  \n",
      "\n",
      "[747 rows x 15 columns]\n",
      "\n",
      "718    5\n",
      "196    5\n",
      "482    5\n",
      "590    2\n",
      "898    2\n",
      "793    2\n",
      "345    5\n",
      "582    5\n",
      "886    5\n",
      "138    5\n",
      "913    5\n",
      "169    5\n",
      "475    5\n",
      "152    5\n",
      "20     2\n",
      "957    5\n",
      "222    5\n",
      "534    5\n",
      "236    5\n",
      "175    2\n",
      "555    5\n",
      "662    5\n",
      "991    5\n",
      "645    5\n",
      "216    5\n",
      "226    7\n",
      "939    5\n",
      "646    5\n",
      "701    5\n",
      "541    2\n",
      "      ..\n",
      "299    2\n",
      "817    5\n",
      "38     5\n",
      "248    5\n",
      "987    5\n",
      "280    5\n",
      "106    5\n",
      "491    5\n",
      "302    2\n",
      "283    5\n",
      "593    4\n",
      "407    5\n",
      "502    5\n",
      "444    5\n",
      "31     5\n",
      "151    6\n",
      "298    5\n",
      "109    5\n",
      "810    2\n",
      "61     5\n",
      "917    5\n",
      "827    5\n",
      "621    5\n",
      "536    5\n",
      "84     5\n",
      "512    8\n",
      "740    5\n",
      "414    5\n",
      "128    5\n",
      "815    5\n",
      "Name: genre_label, Length: 747, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import re\n",
    "plt.show()\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from sklearn.preprocessing import *\n",
    "from numpy import argmax\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize\n",
    "import codecs\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "#testing with codecs to open a html file, not necessarily needed though.\n",
    "import codecs\n",
    "#data1 = codecs.open('/Users/sidraaziz/PycharmProjects/MLProject/Gutenberg_19th_century_English_Fiction/pg11CarolAlice-content.html','r')\n",
    "#print(data1.read())\n",
    "\n",
    "dataset = pd.read_csv(r'/Users/sidraaziz/PycharmProjects/ProjectGutenberg/Gutenberg_Features3.csv', sep=',', engine='python')\n",
    "dataset.fillna(value = 0, inplace=True)\n",
    "\n",
    "#Now dataframe created above can be split into Features (X) and Target class (y)\n",
    "le_target = LabelEncoder()\n",
    "obj_dataset= dataset.select_dtypes(include=['object']).copy()\n",
    "obj_dataset.head()\n",
    "obj_dataset['genre_label'] = le_target.fit_transform(obj_dataset['Target_Class'])\n",
    "\n",
    "print()\n",
    "#print('below is the list seperation with Target_Class encoded:')\n",
    "#print(obj_dataset[['genreLabel', 'Target_Class']])\n",
    "features = ['p_tag_count','comma_count','colon_count','hyphen_count','TTR','Positive','Neutral','Negative','FleschK_score','CC','PRP','PRP$','IN','NNP','period_count']\n",
    "# Separating out the features\n",
    "X = dataset.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = obj_dataset.loc[:,['Target_Class']].values\n",
    "\n",
    "dataset = dataset.drop('Target_Class',axis=1)\n",
    "\n",
    "#print(len(y.data))\n",
    "\n",
    "#onehotencoding on above label encoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "#obj_dataset['genre_label'] = obj_dataset['Target_Class'].values.reshape(len(obj_dataset['Target_Class']), 1)\n",
    "#onehot_encoded = onehot_encoder.fit_transform(obj_dataset['genre_label'].values.reshape(-1,1))\n",
    "onehot_encoded = onehot_encoder.fit_transform(y.reshape(-1,1))\n",
    "\n",
    "#print(onehot_encoded)\n",
    "\n",
    "\n",
    "# invert first example\n",
    "inverted = le_target.inverse_transform([argmax(onehot_encoded)])\n",
    "#print (onehot_encoded[20])\n",
    "\n",
    "y = obj_dataset['genre_label']\n",
    "\n",
    "#print(y)\n",
    "\n",
    "\n",
    "# create training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y, test_size=0.25)\n",
    "#print('Data for X_train before stopword removal:')\n",
    "#print(X_train.shape, y_train.shape)\n",
    "print()\n",
    "#print(X_test.shape, y_test.shape)\n",
    "\n",
    "#print(X_train)\n",
    "print()\n",
    "#print(y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.12802531,  1.94396893,  1.3534892 , ...,  1.38533443,\n",
       "         0.34459564,  1.97659814],\n",
       "       [ 0.33949875,  0.28922912, -0.48391401, ...,  1.02268417,\n",
       "         0.11825591,  0.70414811],\n",
       "       [-0.72870798, -0.41311151, -0.03541401, ..., -0.44343132,\n",
       "        -0.49609478, -0.53368022],\n",
       "       ...,\n",
       "       [ 0.57551824,  2.72122589,  0.42031986, ...,  2.5334037 ,\n",
       "         0.70027235,  2.36421553],\n",
       "       [ 0.09561194,  0.54966461,  0.36968276, ...,  0.14611777,\n",
       "         0.11825591,  0.4169803 ],\n",
       "       [-0.99270015, -0.64064456, -0.22349465, ..., -0.5927579 ,\n",
       "        -0.43142629, -0.88692937]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler = StandardScaler()\n",
    "\n",
    "standardscaler.fit(X_train)\n",
    "X_train = standardscaler.transform(X_train)\n",
    "X_test = standardscaler.transform(X_test)\n",
    "\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25492071, -0.71935733, -0.33923659, ..., -0.32125503,\n",
       "        -0.3667578 , -0.47850113],\n",
       "       [-0.49880751,  0.15635386, -0.60688981, ...,  0.20623626,\n",
       "         0.24759289,  0.05497315],\n",
       "       [ 0.1760334 , -0.44955729, -0.24519627, ..., -0.41628103,\n",
       "        -0.3020893 , -0.04473622],\n",
       "       ...,\n",
       "       [-0.44985532, -0.34604114, -0.57795433, ..., -0.52682149,\n",
       "        -0.23742081, -0.59494204],\n",
       "       [-1.33798792, -1.19644276, -0.68646239, ..., -1.29284744,\n",
       "        -0.52842903, -1.39110032],\n",
       "       [ 1.30455622,  0.94601251,  0.55052953, ...,  0.60185472,\n",
       "         0.1829244 ,  0.72185723]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN with 5 Nearest neighbor result on validation set:\n",
      "Accuracy of our model with 5 neighbours is equal to 79.92 %.\n",
      "\n",
      "-----------------------------------\n",
      "[[  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0  16   0   0  23   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   6   0   0 182   0   1   0]\n",
      " [  0   0   0   0   0   5   0   0   0]\n",
      " [  0   0   0   0   0   7   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   1]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "#Implementing KNN with 5 nearest neighbors on valid set\n",
    "knn5 = Pipeline([\n",
    "        ('clf5', KNeighborsClassifier(n_neighbors=5))])\n",
    "knn5 = knn5.fit(X_train, y_train)\n",
    "y_pred = knn5.predict(X_test)\n",
    "print()\n",
    "print('KNN with 5 Nearest neighbor result on validation set:')\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print('Accuracy of our model with 5 neighbours is equal to ' + str(round(accuracy, 2)) + ' %.')\n",
    "\n",
    "#Classification reports and confusion matrices for test set\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print()\n",
    "print('-----------------------------------')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from imblearn) (0.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=2, Count=111, Percentage=11.145%\n",
      "Class=5, Count=794, Percentage=79.719%\n",
      "Class=8, Count=18, Percentage=1.807%\n",
      "Class=3, Count=6, Percentage=0.602%\n",
      "Class=1, Count=5, Percentage=0.502%\n",
      "Class=6, Count=18, Percentage=1.807%\n",
      "Class=7, Count=36, Percentage=3.614%\n",
      "Class=0, Count=2, Percentage=0.201%\n",
      "Class=4, Count=6, Percentage=0.602%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-352-3d505b0cb5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# summarize performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean Accuracy: %.3f (%.3f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler, BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "#y = label_encoder.fit_transform(target_label)\n",
    "\n",
    "dataset.shape\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# summarize the class distribution\n",
    "target = obj_dataset['genre_label']\n",
    "counter = Counter(target)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(target) * 100\n",
    "    print('Class=%d, Count=%d, Percentage=%.3f%%' % (k, v, per))\n",
    "    \n",
    "obj_dataset.head()\n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model(X_train, y_train, model):\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# define the reference model\n",
    "model = DummyClassifier(strategy='most_frequent')\n",
    "scores = evaluate_model(X_train, y_train, model)\n",
    "\n",
    "# summarize performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/c7/9eb83942f2dfc84503125c93a40fce94a100ea911f033dcb63805cb63fb0/Keras-2.4.2-py2.py3-none-any.whl (170kB)\n",
      "\u001b[K    100% |████████████████████████████████| 174kB 2.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from keras) (1.16.2)\n",
      "Requirement already satisfied: h5py in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: six in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from h5py->keras) (1.12.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/b7/b6de9de9f14b940ad877fb376c6e1f72d6ea924affce04656b0423725e47/tensorflow-2.2.0-cp37-cp37m-macosx_10_11_x86_64.whl (175.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 175.3MB 320kB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 1.6MB/s \n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.5MB/s \n",
      "\u001b[?25hCollecting protobuf>=3.8.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/9347e30e11c040f5ca24f079d6f06485280c49b2a9f894b5400e27d4d6d1/protobuf-3.12.2-cp37-cp37m-macosx_10_9_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 3.0MB/s \n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting gast==0.3.3 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
      "\u001b[K    100% |████████████████████████████████| 460kB 3.2MB/s \n",
      "\u001b[?25hCollecting h5py<2.11.0,>=2.10.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/8b/4d01ae9a9d50a0bcc7b0b9aae41785d8d9de6fa9bba04dc20b1582181d2d/h5py-2.10.0-cp37-cp37m-macosx_10_6_intel.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 2.5MB/s \n",
      "\u001b[?25hCollecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/85/7a/ae480be23b768910a9327c33517ced4623ba88dc035f9ce0206657c353a9/scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.16.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.1)\n",
      "Collecting google-pasta>=0.1.8 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 3.4MB/s \n",
      "\u001b[?25hCollecting astunparse==1.6.3 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.33.1)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/a5/e6c07b08b934831ccb8c98ee335e66b7761c5754ee3cabfe4c11d0b1af28/opt_einsum-3.2.1-py3-none-any.whl (63kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 3.4MB/s \n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/60/8a343ea6e2d8d4d7fb6701a80f27aef7ddadc8a2b26d151937f07c25f321/grpcio-1.30.0-cp37-cp37m-macosx_10_9_x86_64.whl (2.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.8MB 3.1MB/s \n",
      "\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/93/4860cebd5ad3ff2664ad3c966490ccb46e3b88458b2095145bca11727ca4/setuptools-47.3.1-py3-none-any.whl (582kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 3.4MB/s \n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/57/d706964a7e4056f3f2244e16705388c11631fbb53d3e2d2a2d0fbc24d470/google_auth-1.18.0-py2.py3-none-any.whl (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 3.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 3.1MB/s \n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/cd/a0c1f9e4582ea64dddf76c1b808b318d01e3b858a51c715bffab1016ecc7/tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777kB)\n",
      "\u001b[K    100% |████████████████████████████████| 778kB 3.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 3.2MB/s \n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/59/524ffb454d05001e2be74c14745b485681c6ed5f2e625f71d135704c0909/cachetools-4.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/sidraaziz/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Building wheels for collected packages: termcolor, absl-py\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sidraaziz/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sidraaziz/Library/Caches/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "Successfully built termcolor absl-py\n",
      "Installing collected packages: setuptools, pyasn1-modules, cachetools, google-auth, google-auth-oauthlib, absl-py, markdown, grpcio, protobuf, tensorboard-plugin-wit, tensorboard, keras-preprocessing, termcolor, gast, tensorflow-estimator, h5py, scipy, google-pasta, astunparse, opt-einsum, tensorflow\n",
      "  Found existing installation: setuptools 40.8.0\n",
      "    Uninstalling setuptools-40.8.0:\n",
      "      Successfully uninstalled setuptools-40.8.0\n",
      "  Found existing installation: h5py 2.9.0\n",
      "    Uninstalling h5py-2.9.0:\n",
      "      Successfully uninstalled h5py-2.9.0\n",
      "  Found existing installation: scipy 1.2.1\n",
      "    Uninstalling scipy-1.2.1:\n",
      "      Successfully uninstalled scipy-1.2.1\n",
      "Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 gast-0.3.3 google-auth-1.18.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.30.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.2.2 opt-einsum-3.2.1 protobuf-3.12.2 pyasn1-modules-0.2.8 scipy-1.4.1 setuptools-47.3.1 tensorboard-2.2.2 tensorboard-plugin-wit-1.6.0.post3 tensorflow-2.2.0 tensorflow-estimator-2.2.0 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class_weight = {0: 0.22,\n",
    "                1: 0.10,\n",
    "                2: 0.10,\n",
    "                3: 0.10,\n",
    "                4: 0.18,\n",
    "                5: 0.01,\n",
    "                6: 0.10,\n",
    "                7: 0.10,\n",
    "                8: 0.10 }\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define our custom loss function\n",
    "def focal_loss(y_train, y_pred):\n",
    "    gamma = 2.0\n",
    "    alpha = 0.25\n",
    "    pt_1 = tf.where(tf.equal(y_train, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_train, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(20, kernel_initializer='uniform', input_shape=(15,)))\n",
    "model.add(layers.Dense(15, kernel_initializer='uniform', activation = 'relu'))\n",
    "model.add(layers.Dense(13, kernel_initializer='uniform', activation = 'relu'))\n",
    "model.add(layers.Dense(11, kernel_initializer='uniform', activation = 'relu'))\n",
    "model.add(layers.Dense(9, kernel_initializer='uniform'))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "#cce = tf.keras.losses.CategoricalCrossentropy(y_train,y_pred)\n",
    "\n",
    "# Compile our model\n",
    "#adam = Adam(lr=0.0001)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"], optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.12802531  1.94396893  1.3534892  ...  1.38533443  0.34459564\n",
      "   1.97659814]\n",
      " [ 0.33949875  0.28922912 -0.48391401 ...  1.02268417  0.11825591\n",
      "   0.70414811]\n",
      " [-0.72870798 -0.41311151 -0.03541401 ... -0.44343132 -0.49609478\n",
      "  -0.53368022]\n",
      " ...\n",
      " [ 0.57551824  2.72122589  0.42031986 ...  2.5334037   0.70027235\n",
      "   2.36421553]\n",
      " [ 0.09561194  0.54966461  0.36968276 ...  0.14611777  0.11825591\n",
      "   0.4169803 ]\n",
      " [-0.99270015 -0.64064456 -0.22349465 ... -0.5927579  -0.43142629\n",
      "  -0.88692937]]\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.7470\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.2918\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.1058\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.3641\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.5609\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.6198\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.6653\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.6867\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.6533\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.6948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a45c49f28>"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.6787\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.7108\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.6894\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.6827\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.6881\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.7068\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.6801\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.7095\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.7028\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.6921\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.7175\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.6881\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.7229\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.7028\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.7242\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.7189\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.6975\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.7189\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.7108\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.7082\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.7175\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.7135\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.7041\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.7175\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.7108\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.7041\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.5917\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.7149\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.6934\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.6466\n",
      "(249, 9)\n",
      "[1.9084263e-22 9.4659512e-22 6.3476460e-19 ... 8.4476131e-01 8.5671979e-01\n",
      " 8.5930449e-01]\n"
     ]
    }
   ],
   "source": [
    "#print(X_train)\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=64, class_weight=class_weight)\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "\n",
      "[5 2 2 2 2 2 2 2 2 5 2 5 5 2 5 5 6 5 2 5 2 5 2 2 2 2 5 5 2 5 2 5 5 2 7 2 5\n",
      " 5 5 2 7 5 2 2 2 5 5 2 6 5 2 7 5 2 5 2 2 5 7 2 2 5 2 5 5 2 2 2 2 5 2 5 5 2\n",
      " 5 2 2 2 5 2 2 2 2 2 5 5 2 2 2 7 2 2 5 2 5 2 2 2 2 5 2 2 2 2 2 2 5 5 5 2 5\n",
      " 2 5 2 2 6 5 2 2 2 6 5 5 6 5 5 2 2 5 2 2 2 5 2 2 2 2 7 2 2 5 5 2 5 2 2 2 5\n",
      " 2 5 5 2 5 5 2 7 5 2 2 5 2 2 2 5 5 2 2 2 2 5 2 2 5 6 2 5 5 2 2 2 5 5 2 2 2\n",
      " 5 2 2 2 2 2 5 2 7 6 2 5 2 5 2 2 5 2 2 7 5 2 6 5 7 5 5 5 5 7 2 5 2 5 5 5 5\n",
      " 2 2 2 2 2 5 2 5 5 2 5 2 5 5 2 5 2 5 5 5 2 5 2 5 5 5 2]\n",
      "Confusion Matrix\n",
      "[[ 0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0 37  0  0  2  0  0  0]\n",
      " [ 0  0  1  0  0  1  0  0  0]\n",
      " [ 0  0  1  0  0  1  0  0  0]\n",
      " [ 0  0 85  0  0 88  6 10  0]\n",
      " [ 0  0  0  0  0  4  1  0  0]\n",
      " [ 0  0  5  0  0  1  0  1  0]\n",
      " [ 0  0  3  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "#Classification reports and confusion matrices for test set\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print()\n",
    "print('-----------------------------------')\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "#Confution Matrix and Classification Report\n",
    "#Y_pred = model.predict_generator(validation_generator, num_of_test_samples // batch_size+1)\n",
    "Y_pred = np.argmax(y_pred, axis=1)\n",
    "print(Y_pred)\n",
    "print('Confusion Matrix')\n",
    "c_m = confusion_matrix(y_test,Y_pred)\n",
    "print(c_m)\n",
    "#print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "#print('Classification Report')\n",
    "#target_names = ['Cats', 'Dogs', 'Horse']\n",
    "#print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "#print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
