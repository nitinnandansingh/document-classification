{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "MLPEvaluation.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIoldk7BBmdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "3f3bff65-ea6c-4337-b25f-43da2f880e42"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, BorderlineSMOTE\n",
        "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "#from sklearn.metrics.roc_auc_score\n",
        "from sklearn import svm\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "\n",
        "scaler = StandardScaler()  \n",
        "\n",
        "X = pd.read_csv('features.csv',encoding='windows-1252',sep=',')\n",
        "\n",
        "X.fillna(value=0, inplace=True)\n",
        "\n",
        "X.guten_genre = pd.factorize(X.guten_genre)[0]\n",
        "X['index1'] = X.index\n",
        "\n",
        "#y = X.guten_genre#.get_dummies()\n",
        "y = X.guten_genre #dumiies\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(X.guten_genre)\n",
        "\n",
        "print(y)\n",
        "\n",
        "X = X.drop('guten_genre', 1)\n",
        "\n",
        "X.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " ...\n",
            " [1 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p_tag_count</th>\n",
              "      <th>comma_count</th>\n",
              "      <th>colon_count</th>\n",
              "      <th>hyphen_count</th>\n",
              "      <th>TTR</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>Negative</th>\n",
              "      <th>FleschK_score</th>\n",
              "      <th>CC</th>\n",
              "      <th>PRP</th>\n",
              "      <th>PRP$</th>\n",
              "      <th>IN</th>\n",
              "      <th>NNP</th>\n",
              "      <th>period_count</th>\n",
              "      <th>index1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2283</td>\n",
              "      <td>5669</td>\n",
              "      <td>18</td>\n",
              "      <td>850</td>\n",
              "      <td>0.154</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.673</td>\n",
              "      <td>0.133</td>\n",
              "      <td>51.398</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>688.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>382883</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>268</td>\n",
              "      <td>962</td>\n",
              "      <td>54</td>\n",
              "      <td>311</td>\n",
              "      <td>0.348</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.651</td>\n",
              "      <td>0.118</td>\n",
              "      <td>41.849</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>104178</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3510</td>\n",
              "      <td>11771</td>\n",
              "      <td>415</td>\n",
              "      <td>2664</td>\n",
              "      <td>0.113</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.618</td>\n",
              "      <td>0.142</td>\n",
              "      <td>58.161</td>\n",
              "      <td>23.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>1473.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>821156</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3332</td>\n",
              "      <td>5798</td>\n",
              "      <td>17</td>\n",
              "      <td>1358</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.164</td>\n",
              "      <td>0.729</td>\n",
              "      <td>0.107</td>\n",
              "      <td>64.087</td>\n",
              "      <td>56.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>506644</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>472</td>\n",
              "      <td>1429</td>\n",
              "      <td>39</td>\n",
              "      <td>282</td>\n",
              "      <td>0.262</td>\n",
              "      <td>0.254</td>\n",
              "      <td>0.587</td>\n",
              "      <td>0.159</td>\n",
              "      <td>54.611</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98120</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   p_tag_count  comma_count  colon_count  ...   NNP  period_count  index1\n",
              "0         2283         5669           18  ...  17.0        382883       0\n",
              "1          268          962           54  ...   4.0        104178       1\n",
              "2         3510        11771          415  ...  23.0        821156       2\n",
              "3         3332         5798           17  ...  23.0        506644       3\n",
              "4          472         1429           39  ...   1.0         98120       4\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KPIyXAIBmeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "outputId": "333655f6-f27d-441c-8961-57354b3c4a3a"
      },
      "source": [
        "modeller = TopicModeller()#\n",
        "modeller.setNumberOfTopics(4)\n",
        "modeller.setPercentage(0.1)\n",
        "modeller.loadData( 'prepared_tokens.npy' )\n",
        "\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=0.000001, random_state=None)\n",
        "                    #hidden_layer_sizes=(5, 2), \n",
        "\n",
        "#clf = svm.SVC(kernel='linear')\n",
        "#clf = GaussianNB()\n",
        "\n",
        "sm = SMOTE(random_state = None, k_neighbors=1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "#ros = RandomOverSampler(random_state=None)\n",
        "#rus = RandomUnderSampler(random_state=None)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
        "\n",
        "df_train, df_test = modeller.getFeatures(X_train.index1, X_test.index1)    \n",
        "\n",
        "X_train = X_train.join(df_train)\n",
        "X_test = X_test.join(df_test)\n",
        "X_train.fillna(value=0, inplace=True)\n",
        "X_test.fillna(value=0, inplace=True)\n",
        "print(X_train.head())\n",
        "\n",
        "X_train = X_train.drop('index1',axis=1)\n",
        "X_test = X_test.drop('index1',axis=1)\n",
        "#X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
        "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
        "#X_resampled, y_resampled = ADASYN(n_neighbors=1).fit_resample(X_train, y_train)\n",
        "\n",
        "print(X_resampled.shape)\n",
        "\n",
        "scaler.fit(X_resampled) \n",
        "    \n",
        "X_resampled = scaler.transform(X_resampled)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "clf.fit(X_resampled, y_resampled)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "#y_prob = \n",
        "print(clf.score(X_test, y_test))\n",
        "print(f1_score(y_test,y_pred, average = 'weighted'))\n",
        "y_test = lb.inverse_transform(y_test, threshold=None)\n",
        "y_pred = lb.inverse_transform(y_pred)\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following topics were generated:\n",
            "(0, '0.009*\"ship\" + 0.008*\"captain\" + 0.005*\"boat\" + 0.004*\"deck\"')\n",
            "(1, '0.005*\"horse\" + 0.004*\"mary\" + 0.003*\"count\" + 0.003*\"monsieur\"')\n",
            "(2, '0.003*\"london\" + 0.002*\"secret\" + 0.002*\"george\" + 0.002*\"england\"')\n",
            "(3, '0.004*\"hall\" + 0.003*\"uncle\" + 0.003*\"aunt\" + 0.003*\"train\"')\n",
            "     p_tag_count  comma_count  colon_count  ...  topic1    topic2    topic3\n",
            "841          930         5899          338  ...     0.0  0.000000  0.000000\n",
            "818         2413         8744           62  ...     0.0  0.000000  0.000000\n",
            "797         2145         6513           54  ...     0.0  0.000000  0.000000\n",
            "720         1134         2216          110  ...     0.0  0.999802  0.000000\n",
            "240         1888         3809           41  ...     0.0  0.000000  0.999729\n",
            "\n",
            "[5 rows x 20 columns]\n",
            "(5706, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.615\n",
            "0.727562091503268\n",
            "[[ 10  10   1   0   0   0   1   0]\n",
            " [ 30 125   1   0   0   2   2   0]\n",
            " [  1   2   1   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0]\n",
            " [  1   3   0   0   0   0   0   0]\n",
            " [  4   3   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLaZljYUBmeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class TopicModeller():\n",
        "\n",
        "  def __init__( self ):\n",
        "    self.genres = []\n",
        "    self.books = []\n",
        "    self.NUM_TOPICS = 10\n",
        "    self.PERCENTAGE = 0.2\n",
        "\n",
        "  def setNumberOfTopics( self, value ):\n",
        "    self.NUM_TOPICS = value\n",
        "\n",
        "  def setPercentage( self, value ):\n",
        "    self.PERCENTAGE = value\n",
        "\n",
        "  def loadData( self, path ):\n",
        "    with open(path, 'rb') as f:\n",
        "        self.genres = np.load(f, allow_pickle=True)\n",
        "        self.books = np.load(f, allow_pickle=True)\n",
        "\n",
        "  def getFeatures( self, trainIndices, testIndices ):\n",
        "\n",
        "    books_train, books_test = self.books[trainIndices], self.books[testIndices]\n",
        "    genres_train, genres_test = self.genres[trainIndices], self.genres[testIndices]\n",
        "\n",
        "    arr = []\n",
        "\n",
        "    for i in range( len(genres_train ) ):\n",
        "      if genres_train[i] == 'Literary':\n",
        "        val = random.random()\n",
        "        if val > self.PERCENTAGE:\n",
        "          continue\n",
        "      arr.append( books_train[i])\n",
        "\n",
        "    # Create the topics\n",
        "    NUM_WORDS  = 4\n",
        "\n",
        "    dictionary = corpora.Dictionary( arr )\n",
        "    dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
        "    corpus = [ dictionary.doc2bow( text ) for text in arr ]\n",
        "\n",
        "    # Set training parameters.\n",
        "    num_topics = self.NUM_TOPICS\n",
        "    chunksize = 2000\n",
        "    passes = 20\n",
        "    iterations = 400\n",
        "    eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "    # Make a index to word dictionary.\n",
        "    temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "    id2word = dictionary.id2token\n",
        "\n",
        "    ldamodel = gensim.models.ldamodel.LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=id2word,\n",
        "        chunksize=chunksize,\n",
        "        alpha='auto',\n",
        "        eta='auto',\n",
        "        iterations=iterations,\n",
        "        num_topics=num_topics,\n",
        "        passes=passes,\n",
        "        eval_every=eval_every\n",
        "    )\n",
        "\n",
        "    # Print out the topics\n",
        "    topics = ldamodel.print_topics( num_words=NUM_WORDS )\n",
        "    print(\"The following topics were generated:\")\n",
        "    for topic in topics:\n",
        "      print( topic )\n",
        "\n",
        "    # Process the books and get final training data\n",
        "    X_train = []\n",
        "    Y_train = genres_train # TODO do I have to preprocess it as well?\n",
        "\n",
        "    for book in books_train:\n",
        "\n",
        "      # Get the topic weights\n",
        "      bow = dictionary.doc2bow( book )\n",
        "      topics = ldamodel.get_document_topics( bow )\n",
        "\n",
        "      # Convert the vector of dynamic length to\n",
        "      # constant length feature vector\n",
        "      x = [0] * self.NUM_TOPICS\n",
        "      for topic in topics:\n",
        "        x[topic[0]] = topic[1]\n",
        "      X_train.append(x)\n",
        "\n",
        "    # Prepare our test data in the same way\n",
        "    X_test = []\n",
        "    Y_test = genres_test # TODO do I have to preprocess it as well?\n",
        "\n",
        "    for book in books_test:\n",
        "\n",
        "      # Get the topic weights\n",
        "      bow = dictionary.doc2bow( book )\n",
        "      topics = ldamodel.get_document_topics(bow)\n",
        "\n",
        "      # Convert the vector of dynamic length to\n",
        "      # constant length feature vector\n",
        "      x = [0] * self.NUM_TOPICS\n",
        "      for topic in topics:\n",
        "        x[topic[0]] = topic[1]\n",
        "      X_test.append(x)\n",
        "    df_train = pd.DataFrame()\n",
        "    df_test =  pd.DataFrame()\n",
        "    for i in range(self.NUM_TOPICS):\n",
        "        column = [entity[i] for entity in X_train]\n",
        "        column2 = [entity[i] for entity in X_test]\n",
        "        df_train[\"topic\" + str(i)] = column\n",
        "        df_test[\"topic\" + str(i)] = column2\n",
        "    return df_train, df_test"
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}